# Imports de la biblioth√®que standard
import argparse
import copy
import os
import random
import re
import shutil
import sys
import time
from collections import defaultdict
from datetime import datetime

# Imports de biblioth√®ques tierces
import cv2
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import yaml
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, models, transforms
from tqdm import tqdm

# Imports locaux
import script_pytorch.cnn as cnn


# üìå Cr√©ation dossier logs

def activer_log(dossier_log):
    os.makedirs(dossier_log, exist_ok=True)
    now = datetime.now().strftime('%Y_%m_%d_%H_%M')
    log_filename = os.path.join(dossier_log, f"log_{now}.txt")

    # üìå Redirection des logs vers fichier
    class Logger:
        def __init__(self, stream, filepath):
            self.terminal = stream
            self.log = open(filepath, "a", encoding="utf-8")

        def write(self, message):
            self.terminal.write(message)
            self.log.write(message)

        def flush(self):
            self.terminal.flush()
            self.log.flush()
    sys.stdout = Logger(sys.stdout, log_filename)
    return sys.stdout


def charger_mobilenet(device):

    print("CUDA disponible :", torch.cuda.is_available())
    print("Nom du GPU :", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "Aucun GPU")
    # Charger MobileNetV2 sans la derni√®re couche de classification
    mobilenet = models.mobilenet_v2(pretrained=True)
    mobilenet.classifier = torch.nn.Identity()
    mobilenet.eval()
    return mobilenet.to(device)

# --------------------------------------------------
# üßπ 1. Nettoyage des fichiers invalides
# --------------------------------------------------

def nettoyer_dataset(dataset_dir, classes_folders):
    err_dir = "../dataset_errone"
    os.makedirs(err_dir, exist_ok=True)

    def contient_caracteres_speciaux(texte):
        return bool(re.search(r'[^a-zA-Z0-9_\-\\/\. ]', texte))

    def extension_valide(fichier):
        return os.path.splitext(fichier)[-1].lower() in ['.jpg', '.jpeg', '.png']

    for nom in classes_folders:
            print(f"üîç V√©rification du dossier : {nom}")
            full_class_path = os.path.join(dataset_dir, nom)  # Chemin complet
            for fichier in os.listdir(full_class_path):
                chemin_complet = os.path.join(nom, fichier)
                
                if os.path.isfile(chemin_complet):
                    # üî∏ V√©rification du nom de fichier et de l'extension
                    if contient_caracteres_speciaux(fichier) or not extension_valide(fichier):
                        dest = os.path.join(err_dir, nom)
                        os.makedirs(dest, exist_ok=True)
                        shutil.move(chemin_complet, os.path.join(dest, fichier))
                        print(f"‚ö†Ô∏è Fichier invalide d√©plac√© : {chemin_complet}")

    print(f"‚ö†Ô∏è Nettoyage termin√©")


# --------------------------------------------------
# üßπ 1. Evaluation
# --------------------------------------------------

def compter_references_par_classe(total_images, max_refs=10):

    percentage=0.05

    if total_images <= 0:
        return 0

    num_refs = int(total_images * percentage)
    return min(num_refs, max_refs)

def chercher_references_par_classe(class_dir, required_count):

    reference_images = []

    for fname in os.listdir(class_dir):
        if "reference" in fname.lower() and fname.lower().endswith((".jpg", ".jpeg", ".png")):
            reference_images.append(os.path.join(class_dir, fname))

    if len(reference_images) < required_count:
        raise ValueError(
            f"‚ùå Classe '{os.path.basename(class_dir)}' : {len(reference_images)} image(s) de r√©f√©rence trouv√©e(s), "
            f"il en faut au moins {required_count}. Ajoutez davantage d‚Äôimages avec 'reference' dans le nom."
        )
    
    else:
        print(f"‚úÖ Classe '{os.path.basename(class_dir)}' : {len(reference_images)} image(s) de r√©f√©rence valid√©e(s).")
    return reference_images


def extract_feature(image_path, model, transform, device):
    img = Image.open(image_path).convert("RGB")
    img_tensor = transform(img).unsqueeze(0).to(device)
    with torch.no_grad():
        feat = model(img_tensor).cpu().numpy()[0]
    return feat


def evaluer_dataset(dataset_dir, is_illustration, device, classes_paths, mobilenet, img_height, img_width):
    print("\nüìä √âVALUATION DU DATASET :", dataset_dir)

    # üîß Transformation de l'image pour MobileNet :
    # - Redimensionnement (Resize)
    # - Conversion en tenseur (ToTensor)
    # - Normalisation avec les valeurs d'ImageNet

    preprocess = transforms.Compose([
        transforms.Resize((img_height, img_width)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    class_images = defaultdict(list)

    for class_name in classes_paths:
        full_class_path = os.path.join(dataset_dir, class_name)
        print(f"\nüîé Analyse du dossier : {class_name}")

        if not os.path.isdir(full_class_path):
            print(f"‚ö†Ô∏è Chemin non trouv√© : {full_class_path}")
            continue

        all_files = [f for f in os.listdir(full_class_path)
                     if f.lower().endswith((".png", ".jpg", ".jpeg"))]

        # S√©lection des r√©f√©rences
        required_refs = compter_references_par_classe(len(all_files))
        try:
            reference_paths = chercher_references_par_classe(full_class_path, required_refs)
        except ValueError as e:
            print(e)
            continue

        # Extraction des vecteurs de r√©f√©rence
        reference_features = []
        for ref_path in reference_paths:
            feat = extract_feature(ref_path, mobilenet, preprocess, device)
            reference_features.append(feat)

        reference_features = np.array(reference_features)

        # V√©rification homog√©n√©it√© des r√©f√©rences
        if len(reference_features) >= 2:
            sim_matrix = cosine_similarity(reference_features)
            upper_triangle = sim_matrix[np.triu_indices(len(sim_matrix), k=1)]
            mean_ref_similarity = np.mean(upper_triangle)
            if mean_ref_similarity < 0.7:
                print(f"‚ö†Ô∏è R√©f√©rences trop h√©t√©rog√®nes (score : {mean_ref_similarity:.2f})")
                continue
            else:
                print(f"‚úÖ R√©f√©rences valides (score : {mean_ref_similarity:.2f})")
        else:
            mean_ref_similarity = 1.0

        # √âvaluation des autres images (y compris les r√©f√©rences pour comparaison)
        for fname in all_files:
            img_path = os.path.join(full_class_path, fname)
            feat = extract_feature(img_path, mobilenet, preprocess, device)

            # Homog√©n√©it√© : moyenne de similarit√© avec les r√©f√©rences
            similarities = cosine_similarity([feat], reference_features)[0]
            mean_similarity = np.mean(similarities)

            # Qualit√©
            img = Image.open(img_path).convert("RGB")
            img_resized = img.resize((img_height, img_width))
            img_array = np.array(img_resized)
            gray = cv2.cvtColor(img_array.astype(np.uint8), cv2.COLOR_RGB2GRAY)
            quality_score = np.std(gray) if is_illustration else cv2.Laplacian(gray, cv2.CV_64F).var()

            class_images[class_name].append((fname, mean_similarity, quality_score))

            print(f"‚úÖ Image √©valu√©e : {fname}")

    # Rapport final par classe
    for class_name, items in class_images.items():
        print(f"\nüìÇ Classe : {class_name} | Nombre d‚Äôimages : {len(items)}")

        if not items:
            print("‚ö†Ô∏è Aucune image √† √©valuer.")
            continue

        items.sort(key=lambda x: x[1], reverse=True)  # tri par homog√©n√©it√© d√©croissante

        for fname, sim, qual in items:
            sim_flag = "üî¥ Mauvais" if sim < 0.5 else "üü° Moyen" if sim < 0.7 else "üü¢ Bon" if sim < 0.9 else "üîµ Excellent"
            qual_flag = "üî¥ Mauvais" if qual < 30 else "üü° Moyen" if qual < 50 else "üü¢ Bon" if qual < 100 else "üîµ Excellent"
            is_reference = "‚≠ê" if os.path.join(dataset_dir, class_name, fname) in reference_paths else " "
            print(f"üîπ {fname} {is_reference} | Homog√©n√©it√© : {sim:.4f} ({sim_flag}) | Qualit√© : {qual:.2f} ({qual_flag})")
            #print(f"üîπ {fname} | Homog√©n√©it√© : {sim:.4f} ({sim_flag}) | Qualit√© : {qual:.2f} ({qual_flag})")

        mean_sim = np.mean([sim for _, sim, _ in items])
        mean_qual = np.mean([qual for _, _, qual in items])
        print(f"\nüìä Moyenne homog√©n√©it√© : {mean_sim:.4f}")
        print(f"üìä Moyenne qualit√©     : {mean_qual:.2f}")


def augmenter_dataset(base_path, image_type, augment_path, classes_folders, seed, img_height, img_width):
    print("\nüîÑ AUGMENTATION DES DONN√âES...")

    # Copier tout le dataset original dans le dossier de sortie
    if os.path.exists(augment_path):
        shutil.rmtree(augment_path)  # Supprime l'ancien dossier s'il existe pour √©viter les doublons

    os.makedirs(augment_path, exist_ok=True)

    # üîπ Copier uniquement les dossiers autoris√©s
    for class_name in classes_folders:
        source_dir = os.path.join(base_path, class_name)
        dest_dir = os.path.join(augment_path, class_name)

        if os.path.exists(source_dir):
            shutil.copytree(source_dir, dest_dir)
        else:
            print(f"‚ö†Ô∏è Dossier introuvable : {source_dir}")

    random.seed(seed)
    torch.manual_seed(seed)

    # 1. D√©finir les transformations
    if image_type == "illustration":
        augmentation = transforms.Compose([
            transforms.RandomRotation(degrees=5),
            transforms.RandomResizedCrop(size=img_height, scale=(0.9, 1.0)),
            transforms.RandomApply([transforms.ColorJitter(contrast=0.1)], p=0.7),
            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),
        ])
    else:
        augmentation = transforms.Compose([
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(10),
            transforms.RandomResizedCrop(size=img_height, scale=(0.9, 1.0)),
            transforms.ColorJitter(contrast=0.1)
        ])

    # 2. Rassembler les images par classe
    class_images = defaultdict(list)

    for class_name in classes_folders:
        class_path = os.path.join(augment_path, class_name)
        if not os.path.isdir(class_path):
            continue

        print(f"üîé Traitement de la classe : {class_name}")

        for fname in os.listdir(class_path):
            if fname.lower().endswith((".png", ".jpg", ".jpeg")):
                full_path = os.path.join(class_path, fname)
                class_images[class_name].append(full_path)

    # 3. Calculer combien d‚Äôimages ajouter par classe
    counts = {label: len(paths) for label, paths in class_images.items()}
    max_count = max(counts.values())

    for label, image_paths in class_images.items():
        current_count = len(image_paths)
        extra_needed = max(1, int(current_count * 0.05)) if current_count == max_count else max_count - current_count

        print(f"üîß {label} ‚Üí Ajout de {extra_needed} images")
        save_dir = os.path.join(augment_path, label)
        os.makedirs(save_dir, exist_ok=True)

        # 4. G√©n√©rer des images augment√©es
        for i in tqdm(range(extra_needed), desc=f""):
            path = random.choice(image_paths)
            image = Image.open(path).convert("RGB").resize((img_height, img_width))
            aug_image = augmentation(image)
            aug_image.save(os.path.join(save_dir, f"aug_{i}.jpg"))


def preparer_dataset(classes_autorisees, root_dir, type_images, batch_size, seed, img_height, img_width):

    #train_loader : pour l'apprentissage. Le mod√®le apprend √† classer. Apprendre avec des exercices. donn√©es vues par le mod√®le pendant l'apprentissage.
    #val_loader : √©valuation pendant l'entra√Ænement, souvent pour d√©tecter l‚Äôoverfitting. . pour surveiller la convergence / overfitting. V√©rifie les progr√®s √† chaque √©poque d‚Äôentra√Ænement. Faire des exercices similaires pour voir si tu progresses.
    #test_loader : donn√©es jamais vues par le mod√®le, utilis√©es √† la toute fin pour l‚Äô√©valuation finale. .pour √©valuer la g√©n√©ralisation. Mesure la vraie performance finale.  Prouver que tu ma√Ætrises vraiment, avec des questions nouvelles.

    print(f"\nüîÑ Pr√©paration du dataset : {root_dir}")
    print(f"üîé Classes autoris√©es : {classes_autorisees}")
    
    torch.manual_seed(seed)

    # Transformation en fonction du type d'image
    if type_images == "illustration":
        transform = transforms.Compose([
            transforms.Resize((img_height, img_width)),
            transforms.ToTensor(),
        ])
    else:  # photo
        transform = transforms.Compose([
            transforms.Resize((img_height, img_width)),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
        ])
    
    # üîπ V√©rifier uniquement les dossiers autoris√©s
    dossiers_a_garder = [d for d in os.listdir(root_dir) if d in classes_autorisees]
    if not dossiers_a_garder:
        raise ValueError("‚ùå Aucune classe valide trouv√©e dans le dataset. V√©rifiez le fichier de config.")
    
    # üîπ Cr√©er un dataset temporaire pour charger les images
    full_dataset = datasets.ImageFolder(root=root_dir, transform=transform)
    
    total_images = len(full_dataset)
    print(full_dataset.class_to_idx)
    print(total_images)
    # Calculer les longueurs de chaque split
    train_len = int(0.7 * total_images)
    val_len = int(0.15 * total_images)
    test_len = total_images - train_len - val_len

    # Diviser le dataset
    train_ds, val_ds, test_ds = random_split(full_dataset, [train_len, val_len, test_len])

    # Cr√©er les DataLoaders
    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=batch_size)
    test_loader = DataLoader(test_ds, batch_size=batch_size)

    return train_loader, val_loader, test_loader

# --- Fonction de cr√©ation ---
def creer_modele(image_type: str, num_classes: int, device):
    print(f"üß† Cr√©ation mod√®le : type={image_type}")
    if image_type == "illustration":
        model = cnn.CNNIllustration(num_classes)
    else:
        model = cnn.CNNPhoto(num_classes)

    print("CUDA disponible :", torch.cuda.is_available())
    print("Nom du GPU :", device)
    return model.to(device)

def compter_nombre_images(aug_temp_dir, classes_folders):
    total_images = 0

    for classe in classes_folders:
        dossier_classe = os.path.join(aug_temp_dir, classe)
        total_images += len(os.listdir(dossier_classe))

    return total_images

"""
def compter_nombre_images(aug_temp_dir):
    total_images = 0

    for dossier in os.listdir(aug_temp_dir):
        chemin_dossier = os.path.join(aug_temp_dir, dossier)
        if os.path.isdir(chemin_dossier):
            total_images += len(os.listdir(chemin_dossier))

    return total_images
"""


def calculer_nombre_epochs(nombre_images, nombre_classes, type_image):
 
    base_images = 1000        # R√©f√©rence : 1000 images
    base_classes = 10         # R√©f√©rence : 10 classes
    base_epochs = 30          # 30 √©poques pour la base

    # Facteurs multiplicateurs
    facteur_images = nombre_images / base_images
    facteur_classes = (nombre_classes / base_classes) ** 0.5  # racine carr√©e : √©vite la croissance explosive
    facteur_type = 1.3 if type_image == "illustration" else 1.0

    epochs = int(base_epochs * facteur_images * facteur_classes * facteur_type)

    # Plafond et plancher pour √©viter les extr√™mes
    epochs = max(10, min(epochs, 500))

    return epochs

def entrainer_modele(model, train_loader, val_loader, epochs, learning_rate, device, model_path_name):

    #val_loss = √Ä quel point le mod√®le est s√ªr de ses pr√©dictions (m√™me s‚Äôil se trompe).
    #val_accuracy = √Ä quel point le mod√®le a raison (peu importe la confiance dans sa pr√©diction).

    #val_loss est une valeur positive flottante (souvent 0.1 ‚Äì 2.0, mais peut √™tre bien plus si le mod√®le est instable).
    #val_acc est entre 0 et 1 (0‚Äì100% exprim√© en ratio).

    print("CUDA disponible :", torch.cuda.is_available())
    print("Nom du GPU :", device)
    model.to(device)
    #patience = round(epochs/4)
    patience = 10
    poids = 2.0  # üîß Poids de l'accuracy dans le score global (ajustable)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    meilleur_modele = copy.deepcopy(model.state_dict())
    meilleure_val_loss = float('inf')
    epochs_sans_am√©lioration = 0

    train_losses, val_losses = [], []
    train_accuracies, val_accuracies = [], []

    for epoch in range(epochs):
        print(f"\nüîÅ √âpoque {epoch+1}/{epochs}")
        model.train()
        total_train_loss = 0
        correct = 0
        total = 0

        for inputs, labels in tqdm(train_loader, desc="Entra√Ænement"):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            #print("Sortie mod√®le :", outputs[0])
            #print("Sortie mod√®le :", outputs[:2])
            #print(f"\nLabels batch :", labels)
            #print(f"\nMax label :", labels.max().item())
            #print(f"\nShape sortie mod√®le :", outputs.shape)

            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

            total_train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        train_acc = correct / total
        val_loss, val_acc = evaluer_modele(model, val_loader, criterion, device, mode="Validation")

        train_losses.append(total_train_loss)
        val_losses.append(val_loss)
        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)

        score = val_loss - (val_acc * poids) # Calcul du score combin√© (plus bas = mieux)

        print(f"‚úÖ Train loss: {total_train_loss:.4f} | Train acc: {train_acc:.2%}")
        print(f"üß™ Val loss: {val_loss:.4f} | Val acc: {val_acc:.2%}")
        print(f"üßÆ Score : {score:.2f}")

        if score < meilleure_val_loss:
            meilleure_val_loss = score
            meilleur_modele = copy.deepcopy(model.state_dict())
            meilleure_epoque = epoch + 1  # +1 car les √©poques sont 0-index√©es
            meilleure_val_acc = val_acc
            meilleure_val_loss_brute = val_loss
            meilleure_val_score = score
            epochs_sans_am√©lioration = 0
            print(f"üíæ Meilleur mod√®le sauvegard√©.")
                #f"(Val Loss : {meilleure_val_loss_brute:.4f} | "
                #f"Val Acc : {meilleure_val_acc:.2%} | "
                #f"Score : {meilleure_val_score:.4f})")

        else:
            epochs_sans_am√©lioration += 1
            print(f"‚è≥ Pas d'am√©lioration ({epochs_sans_am√©lioration}/{patience})")

            if epochs_sans_am√©lioration >= patience:
                print("üõë Early stopping d√©clench√©.")
                break

    # Charger le meilleur mod√®le
    model.load_state_dict(meilleur_modele)
    torch.save(model.state_dict(), model_path_name)
    print(f"\nüèÅ Entra√Ænement termin√©. Meilleur mod√®le √† l'√©poque {meilleure_epoque} "
      f"(Val Loss : {meilleure_val_loss_brute:.4f} | "
      f"Val Acc : {meilleure_val_acc:.2%} | "
      f"Score : {meilleure_val_score:.4f})")

    # Courbes
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label="Train Loss")
    plt.plot(val_losses, label="Val Loss")
    plt.title("Courbe de Loss")
    plt.xlabel("√âpoque")
    plt.ylabel("Loss")
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(train_accuracies, label="Train Acc")
    plt.plot(val_accuracies, label="Val Acc")
    plt.title("Courbe de Pr√©cision")
    plt.xlabel("√âpoque")
    plt.ylabel("Accuracy")
    plt.legend()

    plt.tight_layout()
    plt.show()

    return model

def evaluer_modele(model, dataloader, criterion, device, mode="Test"):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = total_loss / len(dataloader)
    accuracy = correct / total
    print(f"\nüìä [{mode}] Loss : {avg_loss:.4f} | Accuracy : {accuracy:.2%}")
    return avg_loss, accuracy

def supprimer_dossier_temp_aug(aug_temp_dir):

    if os.path.exists(aug_temp_dir):
        shutil.rmtree(aug_temp_dir)
        print(f"üßπ Dossier temporaire supprim√© : {aug_temp_dir}")